{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the NYC Subway Dataset\n",
    "\n",
    "Project connected to the [Udacity Intro to Data Science course](https://www.udacity.com/course/viewer#!/c-ud359-nd).\n",
    "\n",
    "by Victor Ribeiro, October/2015\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0. References\n",
    "\n",
    "**About the Dataset**\n",
    "\n",
    "Turnstile and Weather Variables dataset reports on the cumulative number of entries and exists in the NYC with additional information about the weather. \n",
    "\n",
    "* [Original Dataset](https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv) - data set used throughout the course and used in the report below.\n",
    "* [Improved Dataset](https://www.dropbox.com/s/1lpoeh2w6px4diu/improved-dataset.zip?dl=0) - cleaned-up subset of original dataset with additional variables. [Variables in the dataset](https://s3.amazonaws.com/uploads.hipchat.com/23756/665149/05bgLZqSsMycnkg/turnstile-weather-variables.pdf)\n",
    "\n",
    "**References**\n",
    "\n",
    "* [Mann-Whitney U Test](https://storage.googleapis.com/supplemental_media/udacityu/4332539257/MannWhitneyUTest.pdf) Udacity\n",
    "* [Mann-Whitney U Test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) Wikipedia\n",
    "* [Shapiro-Wilk Test](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test) Wikipedia\n",
    "* [Shapiro-Wild Test](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html) Python reference\n",
    "* [Diez, David; Barr, Christopher; Çetinkaya-Rundel, Mine] OpenIntro Statistics, Third Edition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1. Statistical Test\n",
    "\n",
    "**1.1 Which statistical test did you use to analyze the NYC subway data? Did you use a one-tail or a two-tail P value? What is the null hypothesis? What is your p-critical value?**\n",
    "\n",
    ">Considering the proposed project :\n",
    ">* Null hypothesis : there's no difference between number of rides in the metro during raining days vs. not raining days. \n",
    ">* Alternative hypothesis : there's a difference between number of rides in the metro during raining days vs.\n",
    "not raining days.\n",
    ">\n",
    ">A Mann-Whitney U Test is applied. It's a two-tail test and p-critical value 5% (or 0.05).\n",
    "\n",
    "---\n",
    "**1.2 Why is this statistical test applicable to the dataset? In particular, consider the assumptions that the test is making about the distribution of ridership in the two samples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Taking a look in the data to support decision on 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hour</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>maxpressurei</th>\n",
       "      <th>maxdewpti</th>\n",
       "      <th>mindewpti</th>\n",
       "      <th>minpressurei</th>\n",
       "      <th>meandewpti</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>meanwindspdi</th>\n",
       "      <th>mintempi</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>maxtempi</th>\n",
       "      <th>precipi</th>\n",
       "      <th>thunder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951.000000</td>\n",
       "      <td>131951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65975.000000</td>\n",
       "      <td>10.896158</td>\n",
       "      <td>1095.348478</td>\n",
       "      <td>886.890838</td>\n",
       "      <td>30.031894</td>\n",
       "      <td>57.241302</td>\n",
       "      <td>48.259013</td>\n",
       "      <td>29.892714</td>\n",
       "      <td>52.703526</td>\n",
       "      <td>29.965077</td>\n",
       "      <td>0.167100</td>\n",
       "      <td>0.334245</td>\n",
       "      <td>5.543065</td>\n",
       "      <td>56.169775</td>\n",
       "      <td>64.269729</td>\n",
       "      <td>71.769968</td>\n",
       "      <td>0.172276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38091.117022</td>\n",
       "      <td>6.892084</td>\n",
       "      <td>2337.015421</td>\n",
       "      <td>2008.604886</td>\n",
       "      <td>0.125689</td>\n",
       "      <td>8.770891</td>\n",
       "      <td>11.305312</td>\n",
       "      <td>0.146384</td>\n",
       "      <td>9.943590</td>\n",
       "      <td>0.130461</td>\n",
       "      <td>0.373066</td>\n",
       "      <td>0.471728</td>\n",
       "      <td>1.982441</td>\n",
       "      <td>6.338875</td>\n",
       "      <td>6.568289</td>\n",
       "      <td>7.627218</td>\n",
       "      <td>0.429005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.740000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>29.540000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>29.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32987.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>29.960000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>29.840000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>29.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65975.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>30.030000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>29.910000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>29.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98962.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1109.000000</td>\n",
       "      <td>847.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>29.970000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>30.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>131950.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>51839.000000</td>\n",
       "      <td>45249.000000</td>\n",
       "      <td>30.310000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>30.230000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>30.270000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0           Hour  ENTRIESn_hourly  EXITSn_hourly  \\\n",
       "count  131951.000000  131951.000000    131951.000000  131951.000000   \n",
       "mean    65975.000000      10.896158      1095.348478     886.890838   \n",
       "std     38091.117022       6.892084      2337.015421    2008.604886   \n",
       "min         0.000000       0.000000         0.000000       0.000000   \n",
       "25%     32987.500000       5.000000        39.000000      32.000000   \n",
       "50%     65975.000000      12.000000       279.000000     232.000000   \n",
       "75%     98962.500000      17.000000      1109.000000     847.000000   \n",
       "max    131950.000000      23.000000     51839.000000   45249.000000   \n",
       "\n",
       "        maxpressurei      maxdewpti      mindewpti   minpressurei  \\\n",
       "count  131951.000000  131951.000000  131951.000000  131951.000000   \n",
       "mean       30.031894      57.241302      48.259013      29.892714   \n",
       "std         0.125689       8.770891      11.305312       0.146384   \n",
       "min        29.740000      39.000000      22.000000      29.540000   \n",
       "25%        29.960000      50.000000      38.000000      29.840000   \n",
       "50%        30.030000      57.000000      51.000000      29.910000   \n",
       "75%        30.100000      64.000000      55.000000      29.970000   \n",
       "max        30.310000      70.000000      66.000000      30.230000   \n",
       "\n",
       "          meandewpti  meanpressurei            fog           rain  \\\n",
       "count  131951.000000  131951.000000  131951.000000  131951.000000   \n",
       "mean       52.703526      29.965077       0.167100       0.334245   \n",
       "std         9.943590       0.130461       0.373066       0.471728   \n",
       "min        31.000000      29.640000       0.000000       0.000000   \n",
       "25%        45.000000      29.910000       0.000000       0.000000   \n",
       "50%        54.000000      29.960000       0.000000       0.000000   \n",
       "75%        60.000000      30.050000       0.000000       1.000000   \n",
       "max        68.000000      30.270000       1.000000       1.000000   \n",
       "\n",
       "        meanwindspdi       mintempi      meantempi       maxtempi  \\\n",
       "count  131951.000000  131951.000000  131951.000000  131951.000000   \n",
       "mean        5.543065      56.169775      64.269729      71.769968   \n",
       "std         1.982441       6.338875       6.568289       7.627218   \n",
       "min         1.000000      46.000000      55.000000      58.000000   \n",
       "25%         5.000000      52.000000      60.000000      65.000000   \n",
       "50%         5.000000      54.000000      63.000000      71.000000   \n",
       "75%         6.000000      60.000000      68.000000      78.000000   \n",
       "max        12.000000      70.000000      78.000000      86.000000   \n",
       "\n",
       "             precipi  thunder  \n",
       "count  131951.000000   131951  \n",
       "mean        0.172276        0  \n",
       "std         0.429005        0  \n",
       "min         0.000000        0  \n",
       "25%         0.000000        0  \n",
       "50%         0.000000        0  \n",
       "75%         0.100000        0  \n",
       "max         2.180000        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import pandasql\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import csv\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "import sys\n",
    "from ggplot import *\n",
    "import itertools\n",
    "\n",
    "df = pandas.read_csv(\"turnstile_data_master_with_weather.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DATEn</th>\n",
       "      <th>TIMEn</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DESCn</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>maxpressurei</th>\n",
       "      <th>maxdewpti</th>\n",
       "      <th>...</th>\n",
       "      <th>meandewpti</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>meanwindspdi</th>\n",
       "      <th>mintempi</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>maxtempi</th>\n",
       "      <th>precipi</th>\n",
       "      <th>thunder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>217</td>\n",
       "      <td>553</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>890</td>\n",
       "      <td>1262</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>2451</td>\n",
       "      <td>3708</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>R001</td>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>4400</td>\n",
       "      <td>2501</td>\n",
       "      <td>30.31</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>30.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  UNIT       DATEn     TIMEn  Hour    DESCn  ENTRIESn_hourly  \\\n",
       "0           0  R001  2011-05-01  01:00:00     1  REGULAR                0   \n",
       "1           1  R001  2011-05-01  05:00:00     5  REGULAR              217   \n",
       "2           2  R001  2011-05-01  09:00:00     9  REGULAR              890   \n",
       "3           3  R001  2011-05-01  13:00:00    13  REGULAR             2451   \n",
       "4           4  R001  2011-05-01  17:00:00    17  REGULAR             4400   \n",
       "\n",
       "   EXITSn_hourly  maxpressurei  maxdewpti   ...     meandewpti  meanpressurei  \\\n",
       "0              0         30.31         42   ...             39          30.27   \n",
       "1            553         30.31         42   ...             39          30.27   \n",
       "2           1262         30.31         42   ...             39          30.27   \n",
       "3           3708         30.31         42   ...             39          30.27   \n",
       "4           2501         30.31         42   ...             39          30.27   \n",
       "\n",
       "   fog  rain  meanwindspdi  mintempi  meantempi  maxtempi  precipi  thunder  \n",
       "0    0     0             5        50         60        69        0        0  \n",
       "1    0     0             5        50         60        69        0        0  \n",
       "2    0     0             5        50         60        69        0        0  \n",
       "3    0     0             5        50         60        69        0        0  \n",
       "4    0     0             5        50         60        69        0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bins = 25\n",
    "alpha = 0.75\n",
    "df[df['rain']==0]['ENTRIESn_hourly'].hist(bins = bins, alpha=alpha) \n",
    "df[df['rain']==1]['ENTRIESn_hourly'].hist(bins = bins, alpha=alpha) \n",
    "    \n",
    "plt.suptitle('Histogram of ENTRIESn_hourly')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('ENTRIESn_hourly')\n",
    "plt.legend(['no rain', 'rain'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Histogram Raining and Non-Raining](https://github.com/vfribeiro/IntroDataScience/blob/master/figure_1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As per histogram above neither raining days nor no-raining days data follow a normal distribution. Indeed, by applying Shapiro-Wik test (below), we confirm datasets do not follow normal distribution as p-value for shapiro test on both raining / no-raining data is really small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47661787271499634, 0.0)\n",
      "(0.4715914726257324, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vribeiro/anaconda/lib/python2.7/site-packages/scipy/stats/morestats.py:997: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "print scipy.stats.shapiro(df[df['rain']==0]['ENTRIESn_hourly'])\n",
    "print scipy.stats.shapiro(df[df['rain']==1]['ENTRIESn_hourly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Thus, a non-parametric test like Mann-Whithney U Test is applicable.\n",
    "\n",
    "---\n",
    "**1.3 What results did you get from this statistical test? These should include the following numerical values: p-values, as well as the means for each of the two samples under test.**\n",
    "\n",
    ">Applying Mann-Whitney U Test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105.44637675 1090.27878015 1924409167.0 0.049999825587\n"
     ]
    }
   ],
   "source": [
    "with_rain_mean = np.mean(df[df['rain']==1]['ENTRIESn_hourly'])\n",
    "without_rain_mean = np.mean(df[df['rain']==0]['ENTRIESn_hourly'])\n",
    "    \n",
    "U,p = scipy.stats.mannwhitneyu(df[df['rain']==1]['ENTRIESn_hourly'],\n",
    "                               df[df['rain']==0]['ENTRIESn_hourly'])\n",
    "\n",
    "print with_rain_mean, without_rain_mean, U, 2*p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 What is the significance and interpretation of these results?**\n",
    "\n",
    ">`ENTRIESn_hourly` raining mean is slightly bigger than no-raining means - which makes sense as people may prefer walk if it's not raining (personally, I would guess a much higher difference).2 \\* p-value is slightly below 0.05, thus **null hypothesis is rejected**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2. Linear Regression\n",
    "\n",
    "**2.1 What approach did you use to compute the coefficients theta and produce prediction for ENTRIESn_hourly in your regression model:**\n",
    "- **OLS using Statsmodels or Scikit Learn,**\n",
    "- **Gradient descent using Scikit Learn,**\n",
    "- **Or something different?**\n",
    "\n",
    ">OLS (using Statsmodels) has been selected to predict `ENTRIESn_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45845668581696875"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_regression(features, values):\n",
    "    model = sm.OLS(values,sm.add_constant(features))\n",
    "    results = model.fit()\n",
    "    intercept = results.params[0]\n",
    "    params = results.params[1:]    \n",
    "    \n",
    "    return intercept, params\n",
    "\n",
    "features = df[['Hour','rain','meantempi','minpressurei']] \n",
    "dummy_units = pandas.get_dummies(df['UNIT'], prefix='unit')\n",
    "features = features.join(dummy_units)\n",
    "\n",
    "# Perform linear regression\n",
    "intercept, params = linear_regression(features, df['ENTRIESn_hourly'])\n",
    "    \n",
    "predictions = intercept + np.dot(features, params)\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "    n = ((data - predictions)**2).sum()\n",
    "    d = ((data - data.mean())**2).sum()\n",
    "    \n",
    "    r_squared = 1 - n/d\n",
    "    return r_squared\n",
    "\n",
    "compute_r_squared(df['ENTRIESn_hourly'], predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-3007bdaaac50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Perform linear regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mt_inte\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_para\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ENTRIESn_hourly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mt_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_inte\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_para\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mt_rsqu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_r_squared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ENTRIESn_hourly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# collection with almost all features. Following Ex 5 on Set 3, EXITSn_hourly is not being used.\n",
    "aall_features = ['rain','fog', 'precipi', 'Hour', \n",
    "                 'meanwindspdi',\n",
    "                 'maxtempi', 'mintempi', 'meantempi', \n",
    "                 'maxpressurei', 'minpressurei', 'meanpressurei',\n",
    "                 'maxdewpti', 'mindewpti', 'meandewpti' ]\n",
    "\n",
    "# multiple variables to log results\n",
    "i = 0\n",
    "t_feat = []\n",
    "t_inte = []\n",
    "t_para = []\n",
    "t_pred = []\n",
    "t_rsqu = []\n",
    "t_subs = []\n",
    "log_experiments = []\n",
    "\n",
    "# global max logs and counter\n",
    "r_max = -1\n",
    "s_max = 'none'\n",
    "j = 0\n",
    "\n",
    "# This brute force loop will select all combinations of some specific sizes. \n",
    "# At first, not using dummies variables.\n",
    "for L in range(4,6): #(len(aall_features)+1)):\n",
    "    log_experiments.append(j)\n",
    "    r_max_local = -1\n",
    "    \n",
    "    # for each combination, runs a linear regression, loging data, preserving max\n",
    "    for subset in itertools.combinations(aall_features, L):\n",
    "        t_feat.append(i)\n",
    "        t_inte.append(i)\n",
    "        t_para.append(i)\n",
    "        t_pred.append(i)\n",
    "        t_rsqu.append(i)\n",
    "        t_subs.append(i)\n",
    "        \n",
    "        t_subs[i] = subset\n",
    "        \n",
    "        # Selected features\n",
    "        t_feat[i] = df[[subset[0]]]\n",
    "        for k in range(1,len(subset)):\n",
    "            t_feat[i] = t_feat[i].join(df[[subset[k]]])\n",
    "            \n",
    "        # Perform linear regression\n",
    "        t_inte[i], t_para[i] = linear_regression(t_feat[i], df['ENTRIESn_hourly'])\n",
    "        t_pred[i] = t_inte[i] + np.dot(t_feat[i], t_para[i])\n",
    "        t_rsqu[i] = compute_r_squared(df['ENTRIESn_hourly'], t_pred[i])\n",
    "        \n",
    "        # Saving max for each combination size\n",
    "        if r_max_local < t_rsqu[i]:\n",
    "            r_max_local = t_rsqu[i]\n",
    "            log_experiments[j] = [r_max_local, t_subs[i], i]\n",
    "            \n",
    "        #print 'Test ',i,' Subset:', subset, 'R2:', t_rsqu[i]\n",
    "        i = i+1\n",
    "    \n",
    "    # Saving total max for all combinations size so far\n",
    "    if r_max < r_max_local:\n",
    "        r_max = r_max_local\n",
    "        s_max = log_experiments[j]\n",
    "        \n",
    "    j = j+1\n",
    "        \n",
    "# print Rˆ2 max for each combination size and features used\n",
    "for k in range(0,len(log_experiments)):\n",
    "    print log_experiments[k][0], log_experiments[k][1], log_experiments[k][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  3003  Subset: ('Hour', 'mintempi', 'maxdewpti', 'meandewpti') R2: 0.459513261048\n",
      "Test  3004  Subset: ('Hour', 'maxtempi', 'meantempi', 'maxpressurei', 'maxdewpti') R2: 0.459755485495\n",
      "0.459513261048 ('Hour', 'mintempi', 'maxdewpti', 'meandewpti') + Dummies : UNIT and hour\n",
      "0.459755485495 ('Hour', 'maxtempi', 'meantempi', 'maxpressurei', 'maxdewpti') + Dummies : UNIT and hour\n"
     ]
    }
   ],
   "source": [
    "# now for the best combinations without dummies, add dummies variables\n",
    "log_experiments_dummies = []\n",
    "\n",
    "j = 0\n",
    "for k in log_experiments:\n",
    "    log_experiments_dummies.append(j)\n",
    "    \n",
    "    subset = log_experiments[j][1]\n",
    "    \n",
    "    t_feat.append(i)\n",
    "    t_inte.append(i)\n",
    "    t_para.append(i)\n",
    "    t_pred.append(i)\n",
    "    t_rsqu.append(i)\n",
    "    t_subs.append(i)\n",
    "        \n",
    "    t_subs[i] = subset\n",
    "        \n",
    "    # Selected features + dummies\n",
    "    t_feat[i] = df[[subset[0]]]\n",
    "    for k in range(1,len(subset)):\n",
    "        t_feat[i] = t_feat[i].join(df[[subset[k]]])\n",
    "            \n",
    "    t_feat[i] = t_feat[i].join(pandas.get_dummies(df['UNIT'], prefix='unit'))\n",
    "        \n",
    "    # Perform linear regression\n",
    "    t_inte[i], t_para[i] = linear_regression(t_feat[i], df['ENTRIESn_hourly'])\n",
    "    t_pred[i] = t_inte[i] + np.dot(t_feat[i], t_para[i])\n",
    "    t_rsqu[i] = compute_r_squared(df['ENTRIESn_hourly'], t_pred[i])\n",
    "      \n",
    "    log_experiments_dummies[j] = [t_rsqu[i], t_subs[i], i]\n",
    "            \n",
    "    # Saving global max so far\n",
    "    if r_max < t_rsqu[i]:\n",
    "        r_max = t_rsqu[i]\n",
    "        s_max = log_experiments_dummies[j]    \n",
    "\n",
    "    print 'Test ',i,' Subset:', subset, 'R2:', t_rsqu[i]\n",
    "    i = i+1        \n",
    "    j = j+1\n",
    "\n",
    "    \n",
    "# print Rˆ2 max for each subset with dummies and features used\n",
    "for k in range(0,len(log_experiments_dummies)):\n",
    "    print log_experiments_dummies[k][0], log_experiments_dummies[k][1], '+ Dummies : UNIT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2.2 What features (input variables) did you use in your model? Did you use any dummy variables as part of your features?**\n",
    "\n",
    ">Selected variables were : `UNIT` as dummy variable and :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n"
     ]
    }
   ],
   "source": [
    "print s_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "**2.3 Why did you select these features in your model? We are looking for specific reasons that lead you to believe that the selected features will contribute to the predictive power of your model.**\n",
    "- **Your reasons might be based on intuition. For example, response for fog might be: “I decided to use fog because I thought that when it is very foggy outside people might decide to use the subway more often.”**\n",
    "- **Your reasons might also be based on data exploration and experimentation, for example: “I used feature X because as soon as I included it in my model, it drastically improved my R2 value.”**\n",
    "\n",
    ">As I lived majority of my live in a city without metro, I do not have any strong gut feeling about what are the variables that would influentiated the most. Indeed, I've tried different combinations and results were really different one from each other. Thus, I've decided for some brute force : (i) pick all combinations with 4 and 5 elements and calculate R2 without a dummy variable and then, pick the best results and try with a dummy variable.\n",
    ">\n",
    ">The dummy variable 'UNIT' drastically improves R2 value. Max R2 value was `0.459755485495` for features mentioned in 2.2.\n",
    "\n",
    "---\n",
    "\n",
    "**2.4 What are the parameters (also known as \"coefficients\" or \"weights\") of the non-dummy features in your linear regression model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hour             67.424637\n",
       "maxtempi         47.498094\n",
       "meantempi       -71.922292\n",
       "maxpressurei   -424.532240\n",
       "maxdewpti        12.536417\n",
       "dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_para[3004].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2.5 What is your model’s R2 (coefficients of determination) value?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4597554854950926"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_r_squared(df['ENTRIESn_hourly'], t_pred[3004])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**2.6 What does this R2 value mean for the goodness of fit for your regression model? Do you think this linear model to predict ridership is appropriate for this dataset, given this R2  value?**\n",
    "\n",
    "> R2 is the the percentage of variance that is explained. Max R2 obtained explains only 46% of variation, which is low. Additional study may lead to best results. For instance, more features or polynomial regressions plus regularization to mitigate over-fitting.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3. Visualization\n",
    "\n",
    "**Please include two visualizations that show the relationships between two or more variables in the NYC subway data.\n",
    "Remember to add appropriate titles and axes labels to your plots. Also, please add a short description below each figure commenting on the key insights depicted in the figure.**\n",
    "\n",
    "**3.1 One visualization should contain two histograms: one of  ENTRIESn_hourly for rainy days and one of ENTRIESn_hourly for non-rainy days.**\n",
    "- **You can combine the two histograms in a single plot or you can use two separate plots.**\n",
    "- **If you decide to use to two separate plots for the two histograms, please ensure that the x-axis limits for both of the plots are identical. It is much easier to compare the two in that case.**\n",
    "- **For the histograms, you should have intervals representing the volume of ridership (value of ENTRIESn_hourly) on the x-axis and the frequency of occurrence on the y-axis. For example, each interval (along the x-axis), the height of the bar for this interval will represent the number of records (rows in our data) that have ENTRIESn_hourly that falls in this interval.**\n",
    "- **Remember to increase the number of bins in the histogram (by having larger number of bars). The default bin width is not sufficient to capture the variability in the two samples.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bins = 20\n",
    "alpha = 0.50\n",
    "df[df['rain']==0]['ENTRIESn_hourly'].hist(bins = bins, alpha=alpha) \n",
    "df[df['rain']==1]['ENTRIESn_hourly'].hist(bins = bins, alpha=alpha) \n",
    "    \n",
    "plt.suptitle('Histogram of ENTRIESn_hourly')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('ENTRIESn_hourly')\n",
    "plt.legend(['no rain', 'rain'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Histogram Raining and Non-Raining](https://github.com/vfribeiro/IntroDataScience/blob/master/figure_1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**3.2 One visualization can be more freeform. You should feel free to implement something that we discussed in class (e.g., scatter plots, line plots) or attempt to implement something more advanced if you'd like. Some suggestions are:**\n",
    "- **Ridership by time-of-day**\n",
    "- **Ridership by day-of-week**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4. Conclusion\n",
    "\n",
    "**Please address the following questions in detail. Your answers should be 1-2 paragraphs long.**\n",
    "\n",
    "**4.1 From your analysis and interpretation of the data, do more people ride\n",
    "the NYC subway when it is raining or when it is not raining?**\n",
    "\n",
    ">Yes, according the study here presented, it's possible to conclude with a high level of condifence that more people ride the NYC subway when it's raining than when it's not raining.\n",
    "\n",
    "**4.2 What analyses lead you to this conclusion? You should use results from both your statistical\n",
    "tests and your linear regression to support your analysis.**\n",
    "\n",
    ">In section 1, a full statistical analysis was presented. First, data was analyzed to verify what kind of statistical test could be used. Then, after selecting running Mann-Whitney U Test, obtained p-value leaded to reject the null hypothesis stating no difference between rides when it's raining vs it's not raining.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5. Reflection\n",
    "\n",
    "**Please address the following questions in detail. Your answers should be 1-2 paragraphs long.**\n",
    "\n",
    "**5.1 Please discuss potential shortcomings of the methods of your analysis, including:**\n",
    "- **Dataset,**\n",
    "- **Analysis, such as the linear regression model or statistical test.**\n",
    "\n",
    "**5.2 (Optional) Do you have any other insight about the dataset that you would like to share with us?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
